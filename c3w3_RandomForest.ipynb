{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict the tree cover type using Random Forest\n",
    "The dataset represents the data about trees which were planted in the US (https://archive.ics.uci.edu/ml/datasets/covertype). The dataset consists of the information about 500000 trees. Your aim is to build Random Forest Ensemble to predict the cover type of trees. In order to successfully complete this assignment you have to follow this algorithm:\n",
    "\n",
    "* Load the training data\n",
    "* Transform categorical features into vector representations\n",
    "* Split the dataset into the train and validation part\n",
    "* Fit the Random Forest Ensemble on the training set\n",
    "* Compare accuracy of the fitted model with the Logistic Regression Model, which is about 0.67 for this set\n",
    "\n",
    "If you have enough time, it will be very interesting to dig into further research through these steps:\n",
    "* Determine which features are valuable for your model (calculate feature importance of your model).\n",
    "* Try to reduce the number of trees and see the results.\n",
    "* Understand why the linear models have poor performance on this dataset.\n",
    "\n",
    "The output should be just float number, e.g. 0.67.\n",
    "\n",
    "Notes\n",
    "The dataset is located at /data/covertype2.\n",
    "\n",
    "The metric for this assignment is MultiClass Accuracy. You have to achieve score higher than 71% on the test dataset in order to get the full score for the assignment.\n",
    "\n",
    "### Dataset description\n",
    "\n",
    "<pre>\n",
    "Elevation                               quantitative    meters                       Elevation in meters\n",
    "Aspect                                  quantitative    azimuth                      Aspect in degrees azimuth\n",
    "Slope                                   quantitative    degrees                      Slope in degrees\n",
    "Horizontal_Distance_To_Hydrology        quantitative    meters                       Horz Dist to nearest surface water features\n",
    "Vertical_Distance_To_Hydrology          quantitative    meters                       Vert Dist to nearest surface water features\n",
    "Horizontal_Distance_To_Roadways         quantitative    meters                       Horz Dist to nearest roadway\n",
    "Hillshade_9am                           quantitative    0 to 255 index               Hillshade index at 9am, summer solstice\n",
    "Hillshade_Noon                          quantitative    0 to 255 index               Hillshade index at noon, summer soltice\n",
    "Hillshade_3pm                           quantitative    0 to 255 index               Hillshade index at 3pm, summer solstice\n",
    "Horizontal_Distance_To_Fire_Points      quantitative    meters                       Horz Dist to nearest wildfire ignition points\n",
    "Wilderness_Area (4 binary columns)      qualitative     0 (absence) or 1 (presence)  Wilderness area designation\n",
    "Soil_Type (40 binary columns)           qualitative     0 (absence) or 1 (presence)  Soil Type designation\n",
    "Cover_Type (7 types)                    integer         1 to 7                       Forest Cover Type designation</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.enableHiveSupport().master('local').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler\n",
    "from pyspark.ml.classification import RandomForestClassifier, LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load train dataset located at /data/covertype2 with at least 60 partitions (use function repartition for this case). Use option inferSchema to save numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .option('header', True) \\\n",
    "    .option('inferSchema', True) \\\n",
    "    .format('csv') \\\n",
    "    .load('/data/covertype2') \\\n",
    "    .repartition(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there are two categorical features in dataset: 'Soil_Type' and 'Wild_Type'. You have to transform them into the vector embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "solid_indexer = StringIndexer(inputCol='Soil_Type', outputCol='Soil_Type_enc')\n",
    "wild_indexer = StringIndexer(inputCol='Wild_Type', outputCol='Wild_Type_enc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply OneHotEncoder technique to the dataset in order to get vectors for the Random Forest classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "solid_oh = OneHotEncoder(inputCol='Soil_Type_enc', outputCol='Soil_Type_oh')\n",
    "wild_oh = OneHotEncoder(inputCol='Wild_Type_enc', outputCol='Wild_Type_oh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the VectorAssembler technique to accumulate all features into one vector. Don't forget to use features that you have generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_cols = [\n",
    "    'Soil_Type_oh',\n",
    "    'Wild_Type_oh',\n",
    "    'Elevation',\n",
    "    'Aspect',\n",
    "    'Slope',\n",
    "    'Horizontal_Distance_To_Hydrology',\n",
    "    'Vertical_Distance_To_Hydrology',\n",
    "    'Horizontal_Distance_To_Roadways',\n",
    "    'Hillshade_9am',\n",
    "    'Hillshade_Noon',\n",
    "    'Hillshade_3pm',\n",
    "    'Horizontal_Distance_To_Fire_Points']\n",
    "vector_assembler = VectorAssembler(inputCols=vector_cols, outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.4 ms, sys: 1.44 ms, total: 18.9 ms\n",
      "Wall time: 30 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = Pipeline(stages=[\n",
    "    solid_indexer, \n",
    "    wild_indexer, \n",
    "    solid_oh, \n",
    "    wild_oh,\n",
    "    vector_assembler\n",
    "]).fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the Random Forest model to the train dataset. Don't forget to split dataset into two parts to check your trained models. It is desirable to use about 100 trees with depth about 7 in order to avoid wasting too much time waiting while your model will be fit to the data. Try to adjust the options 'subsamplingRate' and 'featureSubsetStrategy' to get better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rf = RandomForestClassifier(labelCol='Target', featuresCol='features')\n",
    "\n",
    "'''\n",
    "grid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.maxDepth, [7]) \\\n",
    "    .addGrid(rf.numTrees, [10]) \\\n",
    "    .addGrid(rf.subsamplingRate, [0.7, 0.8, 0.9]) \\\n",
    "    .addGrid(rf.featureSubsetStrategy, ['all','sqrt','log2','onethird']) \\\n",
    "    .build()\n",
    "'''\n",
    "    \n",
    "grid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.maxDepth, [7]) \\\n",
    "    .addGrid(rf.numTrees, [10]) \\\n",
    "    .addGrid(rf.subsamplingRate, [0.9]) \\\n",
    "    .addGrid(rf.featureSubsetStrategy, ['onethird']) \\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply model to the validation part of your set and get the accuracy score for the data. Use the MulticlassClassificationEvaluator class from the ml.evaluation module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol='Target', predictionCol='prediction', metricName='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the Cross-Validation to check your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%time\n",
    "rf_cv = CrossValidator(\n",
    "    estimator=rf, \n",
    "    estimatorParamMaps=grid, \n",
    "    evaluator=evaluator, \n",
    "    numFolds=3\n",
    ").fit(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rf_cv.avgMetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are your results better than the results from the Logistic Regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%time\n",
    "(train, test) = df.randomSplit([0.7, 0.3], seed=7)\n",
    "logreg_model = LogisticRegression(labelCol='Target', featuresCol='features').fit(train)\n",
    "logreg_pred = logreg_model.transform(test)\n",
    "print(evaluator.evaluate(logreg_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the feature importances of the trained model. What 5 features are the most important in the dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rf_model.featureImportances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your last cell output must be the accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 117 ms, sys: 21.8 ms, total: 139 ms\n",
      "Wall time: 14min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "(train, test) = df.randomSplit([0.7, 0.3], seed=7)\n",
    "rf_model = RandomForestClassifier(\n",
    "    labelCol='Target', \n",
    "    featuresCol='features',\n",
    "    numTrees=100,\n",
    "    maxDepth=7,\n",
    "    subsamplingRate=0.9,\n",
    "    featureSubsetStrategy='onethird'\n",
    ").fit(train)\n",
    "rf_pred = rf_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7309306092257464"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(rf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
